[{"title":"Python网络爬虫与信息提取","date":"2017-03-30T06:16:22.000Z","path":"2017/03/30/Python网络爬虫与信息提取/","text":"#Python网络爬虫与信息提取这个笔记是跟着北京理工大学计算机学院「嵩天副教授」在中国大学MOOC上的课程《Python网络爬虫与信息提取》所做的学习笔记 ##requests库的get()方法 r = requests.get()其中requests.get()是构造一个向服务器请求资源的Request对象其中r是一个包含服务器资源的Response对象 # -*- coding=UTF-8 -*- # 2017年2月28日17:40:30 import requests url = &apos;http://www.baidu.com&apos; r = requests.get(url) print type(r) #打印r的类型 print r.status_code #打印http请求返回的状态码 print r.headers #打印响应头 运行结果： &lt;class &apos;requests.models.Response&apos;&gt; 200 {&apos;Content-Encoding&apos;: &apos;gzip&apos;, &apos;Transfer-Encoding&apos;: &apos;chunked&apos;, &apos;Set-Cookie&apos;: &apos;BDORZ=27315; max-age=86400; domain=.baidu.com; path=/&apos;, &apos;Server&apos;: &apos;bfe/1.0.8.18&apos;, &apos;Last-Modified&apos;: &apos;Mon, 23 Jan 2017 13:28:26 GMT&apos;, &apos;Connection&apos;: &apos;Keep-Alive&apos;, &apos;Pragma&apos;: &apos;no-cache&apos;, &apos;Cache-Control&apos;: &apos;private, no-cache, no-store, proxy-revalidate, no-transform&apos;, &apos;Date&apos;: &apos;Tue, 28 Feb 2017 09:39:57 GMT&apos;, &apos;Content-Type&apos;: &apos;text/html&apos;} Response对象的属性 属性 说明 r.status_code HTTP请求返回的状态，200表示连接成功，404表示失败 r.text HTTP响应内容的字符串形式。即URL对应的页面内容 r.encoding 从HTTP header中猜测的响应内容编码方式 r.apparent_encoding 从内容中分析出的相应内容编码方式(备选编码方式) r.content HTTP响应内容的二进制形式 一般认为r.apparent_encoding比r.encoding准确 # -*- coding=UTF-8 -*- # 2017-2-28 20:04:57 import requests url = &apos;http://www.baidu.com&apos; r = requests.get(url) print r.encoding #输出encoding的格式 r.encoding = r.apparent_encoding #转换r.text的编码格式 print r.text #输出返回的页面源码 运行结果： ISO-8859-1 &lt;!DOCTYPE html&gt; &lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class=&quot;bg s_ipt_wr&quot;&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class=&quot;bg s_btn_wr&quot;&gt;&lt;input type=submit id=su value=百度一下 class=&quot;bg s_btn&quot;&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(&apos;&lt;a href=&quot;http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=&apos;+ encodeURIComponent(window.location.href+ (window.location.search === &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come=1&quot;)+ &apos;&quot; name=&quot;tj_login&quot; class=&quot;lb&quot;&gt;登录&lt;/a&gt;&apos;);&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=&quot;display: block;&quot;&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; ##爬取网页的通用代码框架Requests库的异常： 异常 说明 requests.ConnectionError 网络连接错误异常，如DNS查询失败、拒绝连接等 requesrs.HTTPError HTTP错误异常 requests.URLRequired URL缺失异常 requests.TooManyRedirects 超过最大重定向次数，产生重定向异常 requests.ConnectTimeout 连接远程服务器超时异常 requests.Timeout 请求URL超时，产生超时异常 r.raise_for_status:如果不是返回状态码不是200，产生异常requests.HTTPError # -*- coding=UTF-8 -*- # 2017-2-28 21:01:51 import requests def GetHTMLText(url): try: r = requests.get(url) #发送HTTP请求 r.raise_for_status #抛出异常 r.encoding = r.apparent_encoding #改变编码方式 return r.text #返回网页内容 except: return &apos;代码异常&apos; if __name__ == &apos;__main__&apos;: url = &apos;http://www.baidu.com&apos; print GetHTMLText(url) ##HTTP协议及Requests库方法Requests库的7个主要方法 方法 说明 requests.request() 构造一个请求，是支撑以下各方法的基础方法 requests.get() 获取HTML网页的主要方法，对应于HTTP的GET requests.head() 获取HTML网页头信息的方法，对应与HTTP的HEAD requests.post() 向HTML网页提交POST请求的方法，对应于HTTP的POST requests.put() 向HTML网页提交PUT请求的方法，对应于HTTP的PUT requests.patch() 向HEML网页提交局部修改请求，对应于HTTP的PATCH requests.delete() 向HTML页面提交删除请求，对应于HTTP的DELETE HTTP协议简介URL格式：http://host[:port][path]host:合法的Internet主机域名或IP地址port:端口号，缺省端口为80path:请求资源的路径 HTTP URL的理解：URL是通过HTTP协议存取资源的Internet路径，一个URL对应一个数据资源 HTTP协议对资源的操作 方法 说明 GET 请求获取URL位置的资源 HEAD 请求获取URL位置资源的响应消息报告，即获得该资源的头部信息 POST 请求向URL位置的资源后附加新的数据 PUT 请求向URL位置存储一个资源，覆盖原URL位置的资源 PATCH 请求局部更新URL位置的资源，即改变该出资源的部分内容 DELETE 请求删除URL位置存储的资源 requests库的head()方法 # -*- coding=UTF-8 -*- # 2017-2-28 21:39:41 import requests url = &apos;http://www.baidu.com&apos; r = requests.head(url) #requests库的head()方法 print r.headers #打印获取的头部信息 运行结果 {&apos;Content-Encoding&apos;: &apos;gzip&apos;, &apos;Server&apos;: &apos;bfe/1.0.8.18&apos;, &apos;Last-Modified&apos;: &apos;Mon, 13 Jun 2016 02:50:34 GMT&apos;, &apos;Connection&apos;: &apos;Keep-Alive&apos;, &apos;Pragma&apos;: &apos;no-cache&apos;, &apos;Cache-Control&apos;: &apos;private, no-cache, no-store, proxy-revalidate, no-transform&apos;, &apos;Date&apos;: &apos;Tue, 28 Feb 2017 13:38:58 GMT&apos;, &apos;Content-Type&apos;: &apos;text/html&apos;} requests库的post()方法 # -*- coding=UTF-8 -*- # 2017-2-28 21:44:35 import requests url = &apos;http://httpbin.org/post&apos; payload = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;} r = requests.post(url, data = payload) #requests库的post()方法 print r.text #打印文件内容 运行结果 { &quot;args&quot;: {}, &quot;data&quot;: &quot;&quot;, &quot;files&quot;: {}, &quot;form&quot;: { &quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot; }, &quot;headers&quot;: { &quot;Accept&quot;: &quot;*/*&quot;, &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, &quot;Content-Length&quot;: &quot;23&quot;, &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;python-requests/2.13.0&quot; }, &quot;json&quot;: null, &quot;origin&quot;: &quot;27.18.150.95&quot;, &quot;url&quot;: &quot;http://httpbin.org/post&quot; } 新增了 &quot;form&quot;: { &quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot; }, ##Requests库主要方法解析Requests库的7个主要方法 方法 说明 requests.request() 构造一个请求，是支撑以下各方法的基础方法 requests.get() 获取HTML网页的主要方法，对应于HTTP的GET requests.head() 获取HTML网页头信息的方法，对应与HTTP的HEAD requests.post() 向HTML网页提交POST请求的方法，对应于HTTP的POST requests.put() 向HTML网页提交PUT请求的方法，对应于HTTP的PUT requests.patch() 向HEML网页提交局部修改请求，对应于HTTP的PATCH requests.delete() 向HTML页面提交删除请求，对应于HTTP的DELETE requests.request(method, url, **kwars) method:请求方式，对应get/put/post等七种 r.requests.request(‘GET’, url, **kmargs) r.requests.request(‘HEAD’, url, **kmargs) r.requests.request(‘POST’, url, **kmargs) r.requests.request(‘PUT’, url, **kmargs) r.requests.request(‘PATCH’, url, **kmargs) r.requests.request(‘delete’, url, **kmargs) r.requests.request(‘OPTIONS’, url, **kmargs) url:拟获取页面的URL链接 **kwargs:控制访问的参数，共13个 params:字典或字节序列，作为参数增加到url中 # -*- coding=UTF-8 -*- # 2017-2-28 21:56:50 import requests url = &apos;http://httpbin.org/post&apos; payload = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;} r = requests.request(&apos;GET&apos;, url, params = payload) #request方法的params参数 print r.url #打印url 运行结果 http://httpbin.org/post?key2=value2&amp;key1=value1 data:字典、字节序列或文件对象，作为Requests的内容 # -*- coding=UTF-8 -*- # 2017-2-28 22:06:00 import requests url = &apos;http://httpbin.org/post&apos; kv = {&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;, &apos;key3&apos;: &apos;value3&apos;} r = requests.request(&apos;POST&apos;, url, data = kv) #request方法的data参数 print r.text #输出对应资源 运行结果 { &quot;args&quot;: {}, &quot;data&quot;: &quot;&quot;, &quot;files&quot;: {}, &quot;form&quot;: { &quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot;, &quot;key3&quot;: &quot;value3&quot; }, &quot;headers&quot;: { &quot;Accept&quot;: &quot;*/*&quot;, &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, &quot;Content-Length&quot;: &quot;35&quot;, &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;python-requests/2.13.0&quot; }, &quot;json&quot;: null, &quot;origin&quot;: &quot;27.18.150.95&quot;, &quot;url&quot;: &quot;http://httpbin.org/post&quot; } json：JSON格式的数据，作为Request的内容 # -*- coding=UTF-8 -*- # 2017-2-28 22:08:57 import requests url = &apos;http://httpbin.org/post&apos; kv = {&apos;key1&apos;: &apos;value1&apos;} r = requests.request(&apos;POST&apos;, url, json = kv) #request方法的json参数 print r.text #输出对应资源 运行结果 { &quot;args&quot;: {}, &quot;data&quot;: &quot;{\\&quot;key1\\&quot;: \\&quot;value1\\&quot;}&quot;, &quot;files&quot;: {}, &quot;form&quot;: {}, &quot;headers&quot;: { &quot;Accept&quot;: &quot;*/*&quot;, &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, &quot;Content-Length&quot;: &quot;18&quot;, &quot;Content-Type&quot;: &quot;application/json&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;python-requests/2.13.0&quot; }, &quot;json&quot;: { &quot;key1&quot;: &quot;value1&quot; }, &quot;origin&quot;: &quot;27.18.150.95&quot;, &quot;url&quot;: &quot;http://httpbin.org/post&quot; } header：字典，HTTP定制头 # -*- coding=UTF-8 -*- # 2017-2-28 22:13:23 import requests url = &apos;http://httpbin.org/post&apos; hd = {&apos;user-agent&apos;: &apos;Chrome/10&apos;} r = requests.request(&apos;POST&apos;, url, headers = hd) #request方法的header参数 print r.headers #输出对应资源 运行结果 {&apos;Content-Length&apos;: &apos;316&apos;, &apos;Server&apos;: &apos;nginx&apos;, &apos;Connection&apos;: &apos;keep-alive&apos;, &apos;Access-Control-Allow-Credentials&apos;: &apos;true&apos;, &apos;Date&apos;: &apos;Tue, 28 Feb 2017 14:11:55 GMT&apos;, &apos;Access-Control-Allow-Origin&apos;: &apos;*&apos;, &apos;Content-Type&apos;: &apos;application/json&apos;} cookies:字典或CookieJar,Request中的cookie auth:元组，支持HTTP认证功能 files:字典类型，传输文件 # -*- coding=UTF-8 -*- # 2017-2-28 22:51:51 import requests url = &apos;http://httpbin.org/post&apos; fs = {&apos;files&apos;: open(&apos;stdin.txt&apos;, &apos;rb&apos;)} r = requests.request(&apos;POST&apos;, url, files = fs) #request方法的files参数 r.encoding = r.apparent_encoding print r.text #输出对应资源 运行结果 { &quot;args&quot;: {}, &quot;data&quot;: &quot;&quot;, &quot;files&quot;: { &quot;files&quot;: &quot;just some test\\r\\nanother&quot; }, &quot;form&quot;: {}, &quot;headers&quot;: { &quot;Accept&quot;: &quot;*/*&quot;, &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, &quot;Content-Length&quot;: &quot;169&quot;, &quot;Content-Type&quot;: &quot;multipart/form-data; boundary=76d625c06e9245209af4d8a44efd9210&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;python-requests/2.13.0&quot; }, &quot;json&quot;: null, &quot;origin&quot;: &quot;27.18.150.95&quot;, &quot;url&quot;: &quot;http://httpbin.org/post&quot; } timeout: 设定超时时间，秒为单位 r = requests.request(&apos;GET&apos;, url, timeout = 10) proxies:字典类型，设定访问代理服务器，可以增加登录认证 pxs = {&apos;http&apos;: &apos;http://user:pass@10.10.10.1:1234&apos;, &apos;https&apos;: &apos;https://10.10.10.1:4321&apos;} r = requests.request(&apos;GET&apos;, &apos;http://www.baidu.com&apos;, proxies=pxs) allow_redirects: True/False，默认为True，重定向开关 stream:True/False, 默认为True，获取内容立即下载开关 verify:True/False, 默认为True，认证SSL证书开关 cert:本地SSL证书路径 requests.get(url, params=None, **kwargs) url:拟获取页面的URL params:url中的额外参数，字典或字节流格式，可选 **kwargs：12个控制访问的参数(除了params) requests.head(url, **kwargs) url:拟获取页面的URL **kwargs：13个控制访问的参数 requests.post(url, data=None, json=None, **kwargs) url:拟获取页面的URL data:字典、字节序列或文件，Request的内容 json：JSON格式的数据，Request的内容 **kwargs：11个控制访问的参数 requests.put(url, data=None, **kwargs) url:拟获取页面的URL data:字典、字节序列或文件，Request的内容 **kwargs：12个控制访问的参数 requests.patch(url, data=None, **kwargs) url:拟获取页面的URL data:字典、字节序列或文件，Request的内容 **kwargs：12个控制访问的参数 requests.delete(url, **kwargs) url:拟获取页面的URL **kwargs：13个控制访问的参数 ##Robots协议作用：网站告知网络爬虫哪些页面可以抓取，哪些不行形式：在网站根目录下的robots.txt文件 ##Requests库的网络爬虫实战 ###实例1：京东商品页面的爬取 # -*- coding=UTF-8 -*- # 2017-3-1 10:33:03 import requests def getHTML(url): try: r = requests.get(url) #发送HTML请求 r.raise_for_status() #抛出异常 r.encoding = r.apparent_encoding #改变编码 return r.text[:1000] #返回前1000个字符 except: return &apos;程序异常&apos; if __name__ == &apos;__main__&apos;: #执行脚本 url = &apos;https://item.jd.com/2967929.html&apos; print getHTML(url) 运行结果 &lt;!DOCTYPE HTML&gt; &lt;html lang=&quot;zh-CN&quot;&gt; &lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=gbk&quot; /&gt; &lt;title&gt;【华为荣耀8】荣耀8 4GB+64GB 全网通4G手机 魅海蓝【行情 报价 价格 评测】-京东&lt;/title&gt; &lt;meta name=&quot;keywords&quot; content=&quot;HUAWEI荣耀8,华为荣耀8,华为荣耀8报价,HUAWEI荣耀8报价&quot;/&gt; &lt;meta name=&quot;description&quot; content=&quot;【华为荣耀8】京东JD.COM提供华为荣耀8正品行货，全国价格最低，并包括HUAWEI荣耀8网购 指南，以及华为荣耀8图片、荣耀8参数、荣耀8评论、荣耀8心得、荣耀8技巧等信息，网购华为荣耀8上京东,放心又轻松&quot; /&gt; &lt;meta name=&quot;format-detection&quot; content=&quot;telephone=no&quot;&gt; &lt;meta http-equiv=&quot;mobile-agent&quot; content=&quot;format=xhtml; url=//item.m.jd.com/product/2967929.html&quot;&gt; &lt;meta http-equiv=&quot;mobile-agent&quot; content=&quot;format=html5; url=//item.m.jd.com/product/2967929.html&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=Edge&quot;&gt; &lt;link rel=&quot;canonical&quot; href=&quot;//item.jd.com/2967929.html&quot;/&gt; &lt;link rel=&quot;dns-prefetch&quot; href=&quot;//misc.360buyimg.com&quot;/&gt; &lt;link rel=&quot;dns-prefetch&quot; href=&quot;//static.360buyimg.com&quot;/&gt; &lt;link rel=&quot;dns-prefetch&quot; href=&quot;//img10.360buyimg.com&quot;/&gt; &lt;link rel=&quot;dns-prefetch&quot; hr ###实例2：亚马逊商品页面的爬取","excerpt":"#Python网络爬虫与信息提取这个笔记是跟着北京理工大学计算机学院「嵩天副教授」在中国大学MOOC上的课程《Python网络爬虫与信息提取》所做的学习笔记","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"Spider","slug":"Spider","permalink":"http://yoursite.com/tags/Spider/"},{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"}]},{"title":"使用yilia主题遇到的一些问题","date":"2017-03-29T13:56:33.000Z","path":"2017/03/29/使用yilia主题遇到的一些问题/","text":"&lt;未完待续&gt; ###1.主页文章如何只显示部分预览，而不是整篇文章yilia主题下发布一篇文章在主页上默认是显示整篇文章的，这个时候如果有几篇文章比较长看起来很难受还不美观。所以我自然而然地想要把它改成预览模式所以就去翻yilia的配置文件啦在blog根目录下执行： vim ./themes/yilia/_config.yml 打开yilia的配置文件经过一番(神TM)推断-.-觉得文章显示全文与否的关键地方应该是这里： # 文章太长，截断按钮文字 excerpt_link: more 虽然看不懂英文，但是看懂了“文章太长”这四个字，然而下面这一句没看懂…..查了一下：excerpt–摘录、引用。 确认是这个但是还是不明白是如何使用它。经过一番天真的猜测，难道是文中出现这个词就会截断，所以叫截断按钮文字？？但是万一文档中本来就要有这个词[more]那不就有二义性了吗=.=先不想那么多，有猜想就试试吧~打开markdown文档，在第一段之后加了more，然后提交更改：hexo g -d然而….并没有预期中的效果，好吧，不是原来想的这个求问度娘0.0 然而…找半天也没看到我这个问题的解决方法，屁颠屁颠跑去知乎提了这个问题，问题挂上去之后又翻了翻度娘，竟然意外翻到了，原来是要把more放在标签里。好吧….我好傻格式是：&lt;!-- more --&gt;在文中要截断的地方加上这个标签就可以在主页上实现预览的效果了，主页里显示到这个标签之前的内容，剩下的内容可以点击展开，效果如下： ###2.如何给文章添加多标签在文章的tag标签下以无序列表的形式列出，比如： --- title: 使用yilia主题遇到的一些问题 date: 2017-03-29 21:56:33 tags: - 笔记 - 技巧 --- 效果如下： 3.如何更改主页的头像到blog根目录下执行命令： vim ./themes/yilia/_config.yml 进入yilia主题的配置文件找到这个： #你的头像url avatar: 添加avatar的值，头像的url这个可以把头像存到github上，然后把github上给出的这个图像的url填上去就可以","excerpt":"&lt;未完待续&gt; ###1.主页文章如何只显示部分预览，而不是整篇文章yilia主题下发布一篇文章在主页上默认是显示整篇文章的，这个时候如果有几篇文章比较长看起来很难受还不美观。所以我自然而然地想要把它改成预览模式","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://yoursite.com/tags/笔记/"},{"name":"技巧","slug":"技巧","permalink":"http://yoursite.com/tags/技巧/"}]},{"title":"密码学的数学基础","date":"2017-03-29T12:03:36.000Z","path":"2017/03/29/密码学的数学基础/","text":"#信息安全的数学基础##目录 信息安全的数学基础 欧几里得算法 扩展欧几里得算法 乘法逆元 素数筛法求素数 快速幂取模 欧拉函数 中国剩余定理 费马定理优化快速冥取模 欧几里得算法gcd() /*@function int gcd(int a, int b)@author ZXLiao@data 2017-3-2 10:28:22@param a integer@param b integer@return Greatest Common Divisor**/ int gcd(int a, int b){ if(b == 0){ return a; } return gcd(b, a % b);} 扩展欧几里得算法extent_gcd() /******************** @function int extend_gcd(int a, int b, int &amp;x, int &amp;y) @author ZXLiao @data 2017-3-2 17:55:32 @param a coefficient_a @param b coefficient_b @param x solution_x @param y solution_y @return gcd(a, b) x y ********************/ int extend_gcd(int a, int b, int &amp;x, int &amp;y){ /* 大前提保证： ①ax + by = gcd(a, b)一定有整数解。 ②bx + (a%b)y = gcd(b, a%b) 与①有相同解 如果b==0；那么方程就是ax=gcd(a, b) = a； 即x = 1；另取y = 0(也可以取其他值)； */ if(b == 0){ x = 1; y = 0; return a; } int gcd = expand_gcd(b, a%b, x, y); int t = x - a/b*y; // 表达式中有x，避免x改变； x = y; y = t; return gcd; //返回的是gcd(a, b); } 乘法逆元mod_inverse() /****************** @function int mod_inverse(int a, int m) @author ZXLiao @data 2017-3-2 18:59:30 @param a @param m mod @return if without the mod_inverse return -1 else return the inverse of a under modulo m ******************/ int mod_inverse(int a, int m){ if(gcd(a, m) != 1){ return -1; } int x, y; extend_gcd(a, m, x, y); return ((x % m + m) % m); } 素数筛法求素数is_Prime() /******************** @function bool is_Prime(int a) @author ZXLiao @data 2017-3-2 22:37:02 @param a integer @return if a is a Prime return true else return false ********************/ #define __MAX 10000 bool Prime[__MAX]; void get_Prime(){ memset(Prime, true, sizeof(Prime)); Prime[0] = false; for(int i = 1; i &lt;= __MAX; i++){ if(Prime[i]){ int item = 2 * i + 1; for(int j = item * item; j &lt;= __MAX; j += (2 * item)){ Prime[j &gt;&gt; 1] = false; } } } } bool is_Prime(int a){ if(a == 2) return true; if(a &amp; 1) return Prime[a &gt;&gt; 1]; else return false; } 快速幂取模quick_pow() /******************** @function int quick_pow(int a, int n, int __MOD) @author ZXLiao @data 2017-3-2 22:53:17 @param a @param n @param __MOD modulo @return (a^n)%__MOD ********************/ int quick_pow(int a, int n, int __MOD){ if(n == 0) return 1; if(n &amp; 1) return a * quick_pow(a, n - 1, __MOD) % __MOD; int t = quick_pow(a, n &gt;&gt; 1, __MOD); return t * t % __MOD; } 欧拉函数 #include&lt;cstdio&gt; #include&lt;cstring&gt; #include&lt;cstdlib&gt; #include&lt;iostream&gt; #include&lt;algorithm&gt; #define N 1000005 #define M 78500 //预先算出1000000内的素数个数是78499 using namespace std; bool is_Prime[N]; //用于素数筛法 int Prime[M]; //存放素数 long long int oula[N]; //存放欧拉函数 int p; void Get_Prime(){ //首先筛法筛出1000000以内的素数 memset(is_Prime, 1, sizeof(is_Prime)); is_Prime[0] = is_Prime[1] = 0; for(long long int i = 2; i &lt; N; i++){ if(is_Prime[i]){ for(long long int j = i * i; j &lt; N; j += i){ is_Prime[j] = 0; } } } } void Init(){ p = 0; for(int i = 0; i &lt; N; i++){ if(is_Prime[i]){ Prime[p++] = i; oula[i] = i - 1; } } } int main () { Get_Prime(); //根据布尔数组的值，把素数存在数组内，并且对素数的欧拉函数进行赋值 Init(); /* 欧拉函数递推关系的推导： 对于oula[x]： oula[x] = x *（p1 - 1）/p1 *（p2 - 1）/ p2 *（p3 - 1）/ p3*……*（pn - 1）/pn ① 此时，考虑oula[x/p1]的函数值 一：倘若x/p1此时还有一个素因子p1，那么： oula[x/p1] = x/p1 *（p1 - 1）/p1 *（p2 - 1）/ p2 *（p3 - 1）/ p3*……*（pn - 1）/pn ② 对比①②两式可以得到oula[x] = oula[x/p1] * p1 二：倘若x/p1此时没有素因子p1，那么： oula[x/p1] = x/p1 *（p2 - 1）/ p2 *（p3 - 1）/ p3*……*（pn - 1）/pn ③ 对比①③两式可以得到oula[x] = oula[x/p1] * (p1 - 1) */ oula[0] = oula[1] = 1; //递推初始化 for(int i = 2; i &lt; N; i++){ if(!oula[i]){ //对合数进行欧拉函数求解 for(int j = 0; j &lt; p; j++){ //寻找一个素因子 if(i%Prime[j] == 0){ //找到一个素因子 int k = i/Prime[j]; //记录下i%Prime[j] if(k%Prime[j] == 0){ //对i%Prime[j]再次进行判断，发现可再次整除 oula[i] = oula[k] * Prime[j]; //递推关系 } else{ //递推关系 oula[i] = oula[k] * (Prime[j] - 1); } break; } } } } return 0; } 中国剩余定理 /******************* @function int chinese_remaining_theory(struct data _data[]) @author ZXLiao @data 2017-3-6 09:36:14 @param struct data _data: Congruence equations @return x *******************/ struct data{ int b; int m; }; int chinese_remaining_theory(struct data _data[]){ bool mark = 1; for(int i = 0; i &lt; N; i++){ for(int j = i + 1; j &lt; N; j++){ if(gcd(_data[i].m, _data[j].m) != 1){ mark = 0; break; } } } if(mark == 0){ return -1; } int M = 1; int Mi[N]; int inv[N]; int X = 0; for(int i = 0; i &lt; N; i++){ M *= _data[i].m; } for(int i = 0; i &lt; N; i++){ Mi[i] = M / _data[i].m; } for(int i = 0; i &lt; N; i++){ inv[i] = mod_inverse(Mi[i], _data[i].m); } for(int i = 0; i &lt; N; i++){ X += _data[i].b * inv[i] * Mi[i]; } return X % M; } 费马定理优化快速冥取模 /******************* @function int Format_pow(int a, int n, int __MOD) @author ZXLiao @data 2017-3-6 09:48:44 @param a @param n @param __MOD modulo @return a^n % __MOD *******************/ int Format_pow(int a, int n, int __MOD){ if(gcd(a, __MOD) == 1){ return quick_pow(a, n % (__MOD - 1), __MOD); } return quick_pow(a, n, __MOD); }","excerpt":"#信息安全的数学基础##目录 信息安全的数学基础 欧几里得算法 扩展欧几里得算法 乘法逆元 素数筛法求素数 快速幂取模 欧拉函数 中国剩余定理 费马定理优化快速冥取模","categories":[],"tags":[{"name":"信息安全","slug":"信息安全","permalink":"http://yoursite.com/tags/信息安全/"}]},{"title":"hexo+Github搭建个人博客","date":"2017-03-29T11:43:18.000Z","path":"2017/03/29/hexo-Github搭建个人博客/","text":"&lt;未完待续&gt;","excerpt":"","categories":[],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"http://yoursite.com/tags/环境配置/"}]},{"title":"小计","date":"2017-03-29T09:03:07.000Z","path":"2017/03/29/小计/","text":"NLPer","excerpt":"","categories":[],"tags":[{"name":"小小的思考","slug":"小小的思考","permalink":"http://yoursite.com/tags/小小的思考/"}]}]